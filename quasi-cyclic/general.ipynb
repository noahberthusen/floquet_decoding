{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "import numpy as np\n",
    "from numpy.linalg import matrix_power, matrix_rank\n",
    "import matplotlib.pyplot as plt\n",
    "from mec import make_circle\n",
    "import galois\n",
    "from scipy.sparse import lil_matrix\n",
    "import os\n",
    "from ldpc import bposd_decoder\n",
    "from result import Result, save_new_res, res_to_line\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 8\n",
    "code = [12,3,9,1,2,0,1,11,3,12,2,0,11,6]\n",
    "#code = [9,5,8,4,1,5,8,7,5,9,2,1,9,5]\n",
    "# code = [12,5,10,4,1,0,1,2,5,12,2,0,11,6]\n",
    "#code = [15,5,5,2,3,2,7,6,15,5,0,4,11,6]\n",
    "#code = [30,3,25,3,1,3,22,13,3,30,3,4,11,9]\n",
    "\n",
    "# k = 12\n",
    "# code = [14,7,6,5,6,0,4,13,7,14,0,2,12,8]\n",
    "#code = [18,6,3,4,5,3,7,2,6,18,1,4,16,15]\n",
    "# code = [12,6,3,1,2,3,1,2,12,6,1,4,16,15]\n",
    "\n",
    "\n",
    "# k = 16\n",
    "#code = [15,5,10,3,2,0,9,7,5,15,3,4,16,15]\n",
    "#code = [30,5,5,3,2,5,3,29,5,30,3,4,17,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0.001 error rate, all equal error\n",
    "#muls001=np.array([0,0,1,0,4.29574973,0,3.72796993,0,3.72677149,0,3.89005214,0,3.99232483,0,4.06567307,0,4.50056257,0,4.34609584,0,4.17703894,0,4.67106587,0,4.57802336,0,4.62997696,0,5.65038511,0,5.27687367,0,6.39057363,0,5.62583295,0,6.25768488,0,7.30176588,0,6.79337286,0,7.34345098,0,7.19368032,0,7.85836973,0,8.45210287,0,8.09274835,0,9.94911087,0,10.61948935,0,9.64066608,0,11.52624589,0,11.23228934,0,12.38933908,0,12.30620952,0,13.33238861,0,13.93051327,0,13.33555394,0,14.56815817,0,15.26570976,0,15.89159447,0,15.75822076,0,17.44299357])\n",
    "#probs=np.array([0,0,1,0,0.98935,0,0.98445,0,0.9794,0,0.97428,0,0.96936,0,0.96417,0,0.95988,0,0.95488,0,0.94804,0,0.94411,0,0.93927,0,0.93305,0,0.93091,0,0.92479,0,0.92167,0,0.91542,0,0.91088,0,0.90663,0,0.90235,0,0.89876,0,0.89245,0,0.89077,0,0.88617,0,0.8798,0,0.87445,0,0.87104,0,0.86716,0,0.86585,0,0.85824,0,0.85396,0,0.85079,0,0.84681,0,0.84419,0,0.84061,0,0.83607,0,0.83324,0,0.82874,0,0.82687,0,0.82096])\n",
    "\n",
    "# 0.001 error rate, everything other than CNOT and measurement is 10x less\n",
    "muls001 = np.array([0,0,1,0,2.83437563,0,2.71543645,0,2.66390109,0,2.47514626,0,2.63554603,0,2.8225308,0,3.20738319,0,3.05384743,0,3.01289603,0,3.30535152,0,3.46853617,0,3.30472058,0,3.34178504,0,3.69494846,0,3.74955935,0,3.89150943,0,4.29804057,0,4.622713,0,4.64298887,0,4.83355337,0,4.63747826,0,5.44062479,0,5.48444052,0,6.05625242,0,5.75421291,0,6.06743327,0,6.63790984,0,6.33608196,0,7.24417597,0,6.69331914,0,7.44078094,0,7.59173345,0,8.37524776,0,8.38899217,0,8.80930114,0,9.80709627,0,8.87491589,0,9.62782511,0,9.85953381])\n",
    "probs = np.array([0,0,1,0,0.9914,0,0.98695,0,0.98352,0,0.97772,0,0.97513,0,0.97076,0,0.96652,0,0.96272,0,0.95921,0,0.953,0,0.95141,0,0.94713,0,0.94261,0,0.93912,0,0.93611,0,0.9328,0,0.92833,0,0.9237,0,0.92182,0,0.91651,0,0.91429,0,0.91166,0,0.9062,0,0.90485,0,0.90021,0,0.89659,0,0.89486,0,0.89014,0,0.88899,0,0.88297,0,0.87894,0,0.87727,0,0.87281,0,0.87138,0,0.86613,0,0.86468,0,0.86198,0,0.85793,0,0.85501])\n",
    "idle_error = 0.0002\n",
    "\n",
    "def cyclic_shift_matrix(l):\n",
    "    arr = np.eye(l, dtype=int)\n",
    "    return np.roll(arr, axis=1, shift=1)\n",
    "\n",
    "ell = code[0]\n",
    "m = code[1]\n",
    "\n",
    "x = np.kron(cyclic_shift_matrix(ell), np.eye(m))\n",
    "y = np.kron(np.eye(ell), cyclic_shift_matrix(m))\n",
    "\n",
    "A1 = matrix_power(x, code[2])\n",
    "A2 = matrix_power(y, code[3])\n",
    "A3 = matrix_power(y, code[4])\n",
    "A = ( A1 + A2 + A3 ) % 2\n",
    "\n",
    "B1 = matrix_power(y, code[5])\n",
    "B2 = matrix_power(x, code[6])\n",
    "B3 = matrix_power(x, code[7])\n",
    "B = ( B1 + B2 + B3 ) % 2\n",
    "\n",
    "Hx = np.hstack([A, B]).astype(int)\n",
    "Hz = np.hstack([B.T, A.T]).astype(int)\n",
    "\n",
    "GF = galois.GF(2)\n",
    "arr = GF(Hz.T)\n",
    "k = 2 * (Hz.T.shape[1] - matrix_rank(arr))\n",
    "\n",
    "\n",
    "def par2gen(H):\n",
    "    GF = galois.GF(2)\n",
    "    gfH = GF(H)\n",
    "    gfH_rank = np.linalg.matrix_rank(gfH)\n",
    "\n",
    "    rref_H = gfH.row_reduce()\n",
    "\n",
    "    swaps = []\n",
    "    col_H = rref_H.copy()\n",
    "    for i in range(gfH_rank):\n",
    "        inds = np.where(col_H[i])[0]\n",
    "        pivot = inds[0]\n",
    "        col_H[:,[i,pivot]] = col_H[:,[pivot,i]]\n",
    "        swaps.append((i,pivot))\n",
    "\n",
    "    col_H = col_H[:gfH_rank]\n",
    "    col_G = GF(np.hstack([col_H[:,gfH_rank:].T, np.eye(H.shape[1]-gfH_rank, dtype=int)]))\n",
    "\n",
    "    G = col_G.copy()\n",
    "    for swap in swaps[::-1]:\n",
    "        G[:,[swap[1],swap[0]]] = G[:,[swap[0],swap[1]]]\n",
    "\n",
    "    if (np.any(G @ rref_H[:gfH_rank].T) or np.any(col_G @ col_H.T)):\n",
    "        print(\"FAILED\")\n",
    "        return\n",
    "    return (np.array(G, dtype=int), np.array(col_G, dtype=int))\n",
    "\n",
    "def commute(x, z, n):\n",
    "    # 0 if commute, 1 if anticommute\n",
    "    x1 = x[:n]\n",
    "    x2 = x[n:]\n",
    "    z1 = z[:n]\n",
    "    z2 = z[n:]\n",
    "    return (x1 @ z2 % 2) ^ (x2 @ z1 % 2)\n",
    "\n",
    "def SGSOP(Gx, Gz, n):\n",
    "    # symplectic gram-schmidt orthogonalization procedure\n",
    "    sym_Gx = np.hstack([Gx, np.zeros(Gx.shape, dtype=int)])\n",
    "    sym_Gz = np.hstack([np.zeros(Gz.shape, dtype=int), Gz])\n",
    "    sym_G = np.vstack([sym_Gx, sym_Gz])\n",
    "    logicals = []\n",
    "    generators = []\n",
    "\n",
    "    while(sym_G.shape[0]):\n",
    "        g1 = sym_G[0]\n",
    "\n",
    "        commutes = True\n",
    "        for i in range(1, sym_G.shape[0]-1):\n",
    "            g2 = sym_G[i]\n",
    "            if (commute(g1,g2,n)):\n",
    "                logicals.append((g1, g2))\n",
    "                sym_G = np.delete(sym_G, [0, i], axis=0)\n",
    "\n",
    "                for j in range(sym_G.shape[0]):\n",
    "                    gj = sym_G[j]\n",
    "                    sym_G[j] = gj ^ (commute(gj,g2,n) * g1) ^ (commute(gj,g1,n) * g2)\n",
    "                commutes = False\n",
    "                break\n",
    "\n",
    "        if commutes:\n",
    "            generators.append(g1)\n",
    "            sym_G = np.delete(sym_G, 0, axis=0)\n",
    "\n",
    "    return (logicals, generators)\n",
    "\n",
    "def get_logicals(gen_type=False):\n",
    "    n = Hx.shape[1]\n",
    "    Gx, col_Gx = par2gen(Hx)\n",
    "    Gz, col_Gz = par2gen(Hz)\n",
    "    logicals, generators = SGSOP(Gx, Gz, n)\n",
    "\n",
    "    logX = np.array([l[1][n:] for l in logicals])\n",
    "    logZ = np.array([l[0][:n] for l in logicals])\n",
    "\n",
    "    if gen_type: return logX\n",
    "    else: return logZ\n",
    "\n",
    "def manhattan(qbts):\n",
    "    p, q = qbts\n",
    "    return np.abs(p[0]-q[0])+np.abs(p[1]-q[1])\n",
    "\n",
    "def embed_code(code, init):\n",
    "    emb_m, emb_ell, A_ind, B_ind = code\n",
    "\n",
    "    lattice = np.empty((2*emb_m, 2*emb_ell), dtype=object)\n",
    "    lattice[0][0] = f\"x{init}\"\n",
    "\n",
    "    # As = [[A1, A2.T], [A2, A3.T], [A1, A3.T]]\n",
    "    # Bs = [[B1, B2.T], [B2, B3.T], [B1, B3.T]]\n",
    "    As = [[A1, A2.T], [A2, A1.T], [A2, A3.T], [A3, A2.T], [A1, A3.T], [A3, A1.T]]\n",
    "    Bs = [[B1, B2.T], [B2, B1.T], [B2, B3.T], [B3, B2.T], [B1, B3.T], [B3, B1.T]]\n",
    "\n",
    "    def get_nbr(i, j):\n",
    "        if (i % 2 == 0):\n",
    "            if (j % 2 == 0):\n",
    "                return \"x\"\n",
    "            else:\n",
    "                return \"r\"\n",
    "        else:\n",
    "            if (j % 2 == 0):\n",
    "                return \"l\"\n",
    "            else:\n",
    "                return \"z\"\n",
    "\n",
    "    for i in range(2*emb_m - 1):\n",
    "        for j in range(2*emb_ell):\n",
    "            curr_ind = int(lattice[i][j][1:])\n",
    "\n",
    "            if (i % 2 == 0):\n",
    "                tmp_A = As[A_ind][1]\n",
    "            else:\n",
    "                tmp_A = As[A_ind][0]\n",
    "            if (j % 2 == 0):\n",
    "                tmp_B = Bs[B_ind][1]\n",
    "            else:\n",
    "                tmp_B = Bs[B_ind][0]\n",
    "\n",
    "            lattice[(i+1)%(2*emb_m)][j] = f\"{get_nbr((i+1)%(2*emb_m), j)}{np.where(tmp_A @ np.eye(m*ell)[curr_ind])[0][0]}\"\n",
    "            lattice[i][(j+1)%(2*emb_ell)] = f\"{get_nbr(i, (j+1)%(2*emb_ell))}{np.where(tmp_B @ np.eye(m*ell)[curr_ind])[0][0]}\"\n",
    "\n",
    "    for i in range(2*emb_m):\n",
    "        for j in range(2*emb_ell):\n",
    "            if (lattice[i][j][0] == \"z\"):\n",
    "                lattice[i][j] = f\"z{int(lattice[i][j][1:]) + m*ell}\"\n",
    "            elif (lattice[i][j][0] == \"r\"):\n",
    "                lattice[i][j] = f\"r{int(lattice[i][j][1:]) + m*ell}\"\n",
    "\n",
    "    return lattice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lattice = embed_code((code[8],code[9],code[10],code[11]), 0)\n",
    "\n",
    "all_qbts = {}\n",
    "\n",
    "qbts = np.array([None for i in range(2*m*ell)])\n",
    "for i in range(lattice.shape[0]):\n",
    "    for j in range(lattice.shape[1]):\n",
    "        if lattice[i][j][0] == \"r\" or lattice[i][j][0] == \"l\":\n",
    "            all_qbts[(i,j)] = int(lattice[i][j][1:])\n",
    "            qbts[int(lattice[i][j][1:])] = (i, j)\n",
    "x_checks = np.array([None for i in range(m*ell)])\n",
    "z_checks = np.array([None for i in range(m*ell)])\n",
    "\n",
    "for i in range(lattice.shape[0]):\n",
    "    for j in range(lattice.shape[1]):\n",
    "        if lattice[i][j][0] == \"x\":\n",
    "            all_qbts[(i,j)] = int(lattice[i][j][1:]) + 2*m*ell\n",
    "            x_checks[int(lattice[i][j][1:])] = (i, j)\n",
    "        elif lattice[i][j][0] == \"z\":\n",
    "            all_qbts[(i,j)] = int(lattice[i][j][1:]) + 2*m*ell\n",
    "            z_checks[int(lattice[i][j][1:])-(m*ell)] = (i, j)\n",
    "\n",
    "x_rs = []\n",
    "z_rs = []\n",
    "for i in range(m*ell):\n",
    "    gen_qbts = qbts[np.where(Hx[i])[0]]\n",
    "    x_rs.append(make_circle(gen_qbts)[2])\n",
    "for i in range(m*ell):\n",
    "    gen_qbts = qbts[np.where(Hz[i])[0]]\n",
    "    z_rs.append(make_circle(gen_qbts)[2])\n",
    "\n",
    "lr_x_checks = np.array([], dtype=int)\n",
    "sr_x_checks = np.array([], dtype=int)\n",
    "lr_z_checks = np.array([], dtype=int)\n",
    "sr_z_checks = np.array([], dtype=int)\n",
    "\n",
    "z_check_succ_probs = np.ones(m*ell)\n",
    "x_check_succ_probs = np.ones(m*ell)\n",
    "\n",
    "for i, x_check in enumerate(x_checks):\n",
    "    gen_qbts = qbts[np.where(Hx[i])[0]]\n",
    "\n",
    "    nonlocal_qbts = []\n",
    "    if (x_rs[i] > (min(x_rs)+np.std(x_rs))):\n",
    "        lr_x_checks = np.append(lr_x_checks, i)\n",
    "    else:\n",
    "        sr_x_checks = np.append(sr_x_checks, i)\n",
    "\n",
    "    for qbt in gen_qbts:\n",
    "        x_check_succ_probs[i] *= probs[manhattan([x_check, qbt])+1]\n",
    "\n",
    "for i, z_check in enumerate(z_checks):\n",
    "    gen_qbts = qbts[np.where(Hz[i])[0]]\n",
    "\n",
    "    nonlocal_qbts = []\n",
    "    if (z_rs[i] > min(z_rs)+np.std(z_rs)):\n",
    "        lr_z_checks = np.append(lr_z_checks, i)\n",
    "    else:\n",
    "        sr_z_checks = np.append(sr_z_checks, i)\n",
    "\n",
    "    for qbt in gen_qbts:\n",
    "        z_check_succ_probs[i] *= probs[manhattan([z_check, qbt])+1]\n",
    "\n",
    "adv = sum(np.array(x_rs)[lr_x_checks]) / sum(x_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_x_checks(checks, p, scale=False):\n",
    "    c = stim.Circuit()\n",
    "    c.append(\"H\", [all_qbts[x_checks[x_check]] for x_check in checks])\n",
    "    c.append(\"DEPOLARIZE1\", [all_qbts[x_checks[x_check]] for x_check in checks], p/10)\n",
    "    for x in checks:\n",
    "        gen_qbts = qbts[np.where(Hx[x])[0]]\n",
    "        for qbt in gen_qbts:\n",
    "            path_qbts = [all_qbts[x_checks[x]], all_qbts[qbt]]\n",
    "            c.append(\"CNOT\", path_qbts)\n",
    "            if scale:\n",
    "                c.append(\"DEPOLARIZE2\", path_qbts, p*muls001[manhattan([x_checks[x], qbt])+1])\n",
    "            else:\n",
    "                c.append(\"DEPOLARIZE2\", path_qbts, p)\n",
    "    c.append(\"H\", [all_qbts[x_checks[x_check]] for x_check in checks])\n",
    "    c.append(\"DEPOLARIZE1\", [all_qbts[x_checks[x_check]] for x_check in checks], p/10)\n",
    "    return c\n",
    "\n",
    "def measure_z_checks(checks, p, scale=False):\n",
    "    c = stim.Circuit()\n",
    "    for z in checks:\n",
    "        gen_qbts = qbts[np.where(Hz[z])[0]]\n",
    "        for qbt in gen_qbts:\n",
    "            path_qbts = [all_qbts[qbt], all_qbts[z_checks[z]]]\n",
    "            c.append(\"CNOT\", path_qbts)\n",
    "            if scale:\n",
    "                c.append(\"DEPOLARIZE2\", path_qbts, p*muls001[manhattan([qbt, z_checks[z]])+1])\n",
    "            else:\n",
    "                c.append(\"DEPOLARIZE2\", path_qbts, p)\n",
    "    return c\n",
    "\n",
    "def all_checks():\n",
    "    c = stim.Circuit()\n",
    "    c += measure_z_checks(sr_z_checks, 0, scale=False)\n",
    "    c += measure_z_checks(lr_z_checks, 0, scale=False)\n",
    "    c += measure_x_checks(sr_x_checks, 0, scale=False)\n",
    "    c += measure_x_checks(lr_x_checks, 0, scale=False)\n",
    "    return c\n",
    "\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, num_rounds, lr_time):\n",
    "        self.num_rounds = num_rounds\n",
    "        self.lr_time = lr_time\n",
    "\n",
    "        self.prev_meas_z = np.arange(1, m*ell+1, dtype=int)\n",
    "        self.prev_meas_x = np.arange(m*ell+1, 2*m*ell+1,  dtype=int)\n",
    "        self.curr_meas_z = np.zeros(m*ell, dtype=int)\n",
    "        self.curr_meas_x = np.zeros(m*ell, dtype=int)\n",
    "\n",
    "        self.route_confirmation_z = np.ones(m*ell, dtype=int)\n",
    "        self.route_confirmation_z[lr_z_checks] = 0\n",
    "        self.route_confirmation_x = np.ones(m*ell, dtype=int)\n",
    "        self.route_confirmation_x[lr_x_checks] = 0\n",
    "        self.detector_history = np.zeros(m*ell)\n",
    "\n",
    "        self.c = stim.Circuit()\n",
    "        for key, value in all_qbts.items():\n",
    "            self.c.append(\"QUBIT_COORDS\", value, (key[0],key[1],0))\n",
    "            self.c.append(\"QUBIT_COORDS\", value+(4*m*ell), (key[0],key[1],1))\n",
    "        self.c.append(\"R\", [qbt for qbt in all_qbts.values()])\n",
    "        self.c.append(\"R\", [qbt+(4*m*ell) for qbt in all_qbts.values()])\n",
    "\n",
    "        self.c += all_checks().without_noise()\n",
    "        self.c.append(\"MR\", [all_qbts[z_check] for z_check in z_checks])\n",
    "        self.c.append(\"MR\", [all_qbts[x_check] for x_check in x_checks])\n",
    "\n",
    "    def detectors(self, type):\n",
    "        num_meas = self.c.num_measurements\n",
    "        if not type:\n",
    "            for i, z_check in enumerate(self.curr_meas_z):\n",
    "                coord = z_checks[i]\n",
    "                if z_check:\n",
    "                    self.c.append(\"DETECTOR\", [stim.target_rec(self.curr_meas_z[i]-num_meas-1), stim.target_rec(self.prev_meas_z[i]-num_meas-1)], (coord[0], coord[1], 0))\n",
    "                    self.prev_meas_z[i] = self.curr_meas_z[i]\n",
    "                    self.curr_meas_z[i] = 0\n",
    "        else:\n",
    "            pass # x type checks\n",
    "\n",
    "    def observables(self, type):\n",
    "        for i, logical in enumerate(get_logicals(type)):\n",
    "            incl_qbts = np.where(logical)[0]\n",
    "            incl_qbts = [-j-1 for j in incl_qbts]\n",
    "            self.c.append(\"OBSERVABLE_INCLUDE\", [stim.target_rec(j) for j in incl_qbts], i)\n",
    "\n",
    "    def sr_round(self, with_gate_noise=True, with_synd_noise=True):\n",
    "        curr_sr_z_checks = sr_z_checks[self.route_confirmation_z[sr_z_checks]==1]\n",
    "        curr_sr_x_checks = sr_x_checks[self.route_confirmation_x[sr_x_checks]==1]\n",
    "        self.c += measure_z_checks(curr_sr_z_checks, 0.001 if with_gate_noise else 0, scale=False)\n",
    "        self.c += measure_x_checks(curr_sr_x_checks, 0.001 if with_gate_noise else 0, scale=False)\n",
    "\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[z_checks[z_check]] for z_check in curr_sr_z_checks], 0.001)\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[x_checks[x_check]] for x_check in curr_sr_x_checks], 0.001)\n",
    "\n",
    "        for i, z_check in enumerate(curr_sr_z_checks):\n",
    "            self.c.append(\"M\", all_qbts[z_checks[z_check]])\n",
    "            self.curr_meas_z[z_check] = self.c.num_measurements\n",
    "        for i, z_check in enumerate(sr_z_checks):\n",
    "            self.c.append(\"R\", all_qbts[z_checks[z_check]])\n",
    "        for i, x_check in enumerate(curr_sr_x_checks):\n",
    "            self.c.append(\"M\", all_qbts[x_checks[x_check]])\n",
    "            self.curr_meas_x[x_check] = self.c.num_measurements\n",
    "        for i, x_check in enumerate(sr_x_checks):\n",
    "            self.c.append(\"R\", all_qbts[x_checks[x_check]])\n",
    "\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[z_checks[z_check]] for z_check in sr_z_checks], 0.001/10)\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[x_checks[x_check]] for x_check in sr_x_checks], 0.001/10)\n",
    "\n",
    "\n",
    "    def lr_round(self, with_gate_noise=True, with_synd_noise=True):\n",
    "        curr_sr_z_checks = sr_z_checks[self.route_confirmation_z[sr_z_checks]==1]\n",
    "        curr_sr_x_checks = sr_x_checks[self.route_confirmation_x[sr_x_checks]==1]\n",
    "        curr_lr_z_checks = lr_z_checks[self.route_confirmation_z[lr_z_checks]==1]\n",
    "        curr_lr_x_checks = lr_x_checks[self.route_confirmation_x[lr_x_checks]==1]\n",
    "\n",
    "        curr_z_checks = np.concatenate([curr_sr_z_checks, curr_lr_z_checks])\n",
    "        curr_x_checks = np.concatenate([curr_sr_x_checks, curr_lr_x_checks])\n",
    "        all_z_checks = np.concatenate([sr_z_checks, lr_z_checks])\n",
    "        all_x_checks = np.concatenate([sr_x_checks, lr_x_checks])\n",
    "\n",
    "        self.c += measure_z_checks(curr_z_checks, 0.001 if with_gate_noise else 0, scale=False)\n",
    "        self.c += measure_x_checks(curr_x_checks, 0.001 if with_gate_noise else 0, scale=False)\n",
    "\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[z_checks[z_check]] for z_check in curr_z_checks], 0.001)\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[x_checks[x_check]] for x_check in curr_x_checks], 0.001)\n",
    "\n",
    "        for i, z_check in enumerate(curr_z_checks):\n",
    "            self.c.append(\"M\", all_qbts[z_checks[z_check]])\n",
    "            self.curr_meas_z[z_check] = self.c.num_measurements\n",
    "        for i, z_check in enumerate(all_z_checks):\n",
    "            self.c.append(\"R\", all_qbts[z_checks[z_check]])\n",
    "        for i, x_check in enumerate(curr_x_checks):\n",
    "            self.c.append(\"M\", all_qbts[x_checks[x_check]])\n",
    "            self.curr_meas_x[x_check] = self.c.num_measurements\n",
    "        for i, x_check in enumerate(all_x_checks):\n",
    "            self.c.append(\"R\", all_qbts[x_checks[x_check]])\n",
    "\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[z_checks[z_check]] for z_check in all_z_checks], 0.001/10)\n",
    "        if with_synd_noise: self.c.append(\"X_ERROR\", [all_qbts[x_checks[x_check]] for x_check in all_x_checks], 0.001/10)\n",
    "\n",
    "\n",
    "    def simulate(self):\n",
    "        for i in range(1,self.num_rounds+1):\n",
    "            self.c.append(\"SHIFT_COORDS\", [], (0,0,1))\n",
    "            if (i%self.lr_time==0):\n",
    "                self.c.append(\"DEPOLARIZE1\", [all_qbts[qbt] for qbt in qbts], 0.001) #+2*(code[12]+code[13])*idle_error)\n",
    "\n",
    "                # self.route_confirmation_z[sr_z_checks] = [1 if np.random.random() < z_check_succ_probs[z] else 0 for z in sr_z_checks]\n",
    "                # self.route_confirmation_z[lr_z_checks] = [1 if np.random.random() < z_check_succ_probs[z] else 0 for z in lr_z_checks]\n",
    "                # self.route_confirmation_x[sr_x_checks] = [1 if np.random.random() < x_check_succ_probs[x] else 0 for x in sr_x_checks]\n",
    "                # self.route_confirmation_x[lr_x_checks] = [1 if np.random.random() < x_check_succ_probs[x] else 0 for x in lr_x_checks]\n",
    "                self.route_confirmation_z[sr_z_checks] = 1\n",
    "                self.route_confirmation_z[lr_z_checks] = 1\n",
    "                self.route_confirmation_x[sr_x_checks] = 1\n",
    "                self.route_confirmation_x[lr_x_checks] = 1\n",
    "                self.detector_history = np.vstack([self.detector_history, self.route_confirmation_z])\n",
    "                self.lr_round()\n",
    "            else:\n",
    "                self.c.append(\"DEPOLARIZE1\", [all_qbts[qbt] for qbt in qbts], 0.001) #+2*code[12]*idle_error)\n",
    "                # self.route_confirmation_z[sr_z_checks] = [1 if np.random.random() < z_check_succ_probs[z] else 0 for z in sr_z_checks]\n",
    "                # self.route_confirmation_x[sr_x_checks] = [1 if np.random.random() < x_check_succ_probs[x] else 0 for x in sr_x_checks]\n",
    "                self.route_confirmation_z[sr_z_checks] = 1\n",
    "                self.route_confirmation_z[lr_z_checks] = 0\n",
    "                self.route_confirmation_x[sr_x_checks] = 1\n",
    "                self.route_confirmation_x[lr_x_checks] = 0\n",
    "                self.detector_history = np.vstack([self.detector_history, self.route_confirmation_z])\n",
    "                self.sr_round()\n",
    "            self.detectors(False)\n",
    "\n",
    "        # self.route_confirmation_z = np.ones(m*ell)\n",
    "        # self.route_confirmation_x = np.ones(m*ell)\n",
    "        # self.detector_history = np.vstack([self.detector_history, self.route_confirmation_z])\n",
    "        # self.lr_round(with_gate_noise=False, with_synd_noise=False)\n",
    "        # self.detectors(False)\n",
    "\n",
    "        self.c.append(\"M\",[all_qbts[qbt] for qbt in qbts[::-1]])\n",
    "        self.observables(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Simulation(20, 1)\n",
    "s.simulate()\n",
    "c = s.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round\tnum\t\n",
      "1\t36\t______________________!__!__!_______\n",
      "2\t36\t____________________________________\n",
      "3\t36\t____________________________________\n",
      "4\t36\t_!___________!______________________\n",
      "5\t36\t_!___________!______________________\n",
      "6\t36\t____________________________________\n",
      "7\t36\t____________________________________\n",
      "8\t36\t_!!_________________________________\n",
      "9\t36\t___________________________!________\n",
      "10\t36\t__________________________!______!!_\n",
      "11\t36\t_______________!__!__!______________\n",
      "12\t36\t____________________________________\n",
      "13\t36\t____________________________________\n",
      "14\t36\t____________________________________\n",
      "15\t36\t_____________________!______________\n",
      "16\t36\t_____________________!______________\n",
      "17\t36\t_____________________________!__!___\n",
      "18\t36\t__________________________!_________\n",
      "19\t36\t________________________!_________!!\n",
      "20\t36\t____________________________________\n",
      "\n",
      "observables\t___!_!__\n"
     ]
    }
   ],
   "source": [
    "detector_sampler = c.compile_detector_sampler()\n",
    "one_sample = detector_sampler.sample(shots=1, append_observables=True)[0]\n",
    "\n",
    "ind = 0\n",
    "last = 0\n",
    "\n",
    "print(\"round\\tnum\\t\")\n",
    "for i in range(1,s.num_rounds+1+last):\n",
    "    curr_checks = s.detector_history[i]\n",
    "    num_checks = np.count_nonzero(curr_checks)\n",
    "    timeslice = one_sample[ind:ind+num_checks]\n",
    "    j = 0\n",
    "    print(f\"{i}\\t{num_checks}\\t\", end=\"\")\n",
    "    for check in curr_checks:\n",
    "        if check:\n",
    "            if timeslice[j]: print(\"!\", end=\"\")\n",
    "            else: print(\"_\", end=\"\")\n",
    "            j += 1\n",
    "        else: print(\" \", end=\"\")\n",
    "    ind += num_checks\n",
    "    print()\n",
    "print()\n",
    "print(\"observables\\t\", end=\"\")\n",
    "timeslice = one_sample[-k:]\n",
    "print(\"\".join(\"!\" if e else \"_\" for e in timeslice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 7022)\n",
      "(8, 7022)\n"
     ]
    }
   ],
   "source": [
    "sampler = c.compile_detector_sampler()\n",
    "dem = c.detector_error_model()\n",
    "pcm = lil_matrix((dem.num_detectors, dem.num_errors), dtype=np.bool_)\n",
    "lcm = lil_matrix((dem.num_observables, dem.num_errors), dtype=np.bool_)\n",
    "\n",
    "errors = []\n",
    "channel_probs = [e.args_copy()[0] for e in dem if e.type==\"error\"]\n",
    "for i, error_event in enumerate(c.explain_detector_error_model_errors()):\n",
    "    dets = [det.dem_target.val for det in error_event.dem_error_terms if det.dem_target.is_relative_detector_id()]\n",
    "    obs = [ob.dem_target.val for ob in error_event.dem_error_terms if ob.dem_target.is_logical_observable_id()]\n",
    "    pcm[[dets],i] = 1\n",
    "    lcm[[obs],i] = 1\n",
    "\n",
    "print(pcm.shape)\n",
    "print(lcm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (array([ 224,  551,  877,  945, 1310, 1799, 1948, 2240, 2299, 2388, 3184,\n",
      "       3531, 4069, 4717, 5992], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "bposd_dec = bposd_decoder(\n",
    "    pcm, # the parity check matrix\n",
    "    channel_probs=channel_probs, #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=pcm.shape[1], #the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=min(pcm.shape[0],10) #the osd search depth\n",
    ")\n",
    "\n",
    "\n",
    "detection_events, observable_flips = sampler.sample(1, separate_observables=True)\n",
    "guessed_errors = bposd_dec.decode(detection_events[0])\n",
    "guessed_obs = (lcm @ guessed_errors) % 2\n",
    "success = np.all(observable_flips[0].astype(int) == guessed_obs)\n",
    "print(success, np.where(guessed_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 224  551  877  945 1310]\n",
      "[224]\n",
      "[ 551  877  945 1310 1799 1948]\n",
      "[224 551]\n",
      "[ 877  945 1310 1799 1948 2243 2323 2374 2379]\n",
      "[224 551 877 945]\n",
      "[1310 1799 1948 2240 2243 2245 2271 2388]\n",
      "[ 224  551  877  945 1310]\n",
      "[1799 1948 2240 2243 2245 2271 2388]\n",
      "[ 224  551  877  945 1310]\n",
      "[1799 1948 2240 2243 2245 2271 2388 3183]\n",
      "[ 224  551  877  945 1310 1799 1948]\n",
      "[2243 2323 2388 3184 3531]\n",
      "[ 224  551  877  945 1310 1799 1948 2243 2323 2388]\n",
      "[3183 3529 3531 4069]\n",
      "[ 224  551  877  945 1310 1799 1948 2243 2323 2388]\n",
      "[3183 3529 3531 4069]\n",
      "[ 224  551  877  945 1310 1799 1948 2243 2323 2388]\n",
      "[3184 3531 4069 4717]\n",
      "[ 224  551  877  945 1310 1799 1948 2243 2323 2388 3184]\n"
     ]
    }
   ],
   "source": [
    "def decode_window(init_synd, window_size):\n",
    "    num_rounds = len(init_synd) // (m*ell) # assumes every gen is measured every round\n",
    "    guessed_errors = np.zeros(dem.num_errors, dtype=np.bool_)\n",
    "    synd = init_synd.copy()\n",
    "    \n",
    "    for r in range(10):\n",
    "        start_error = max(pcm[(r-1)*m*ell:r*m*ell].nonzero()[1]) if r else 0\n",
    "        next_start_error = max(pcm[r*m*ell:(r+1)*m*ell].nonzero()[1])\n",
    "        end_error = max(pcm[r*m*ell:(r+window_size)*m*ell].nonzero()[1])\n",
    "        window_pcm = pcm[r*m*ell:(r+window_size)*m*ell][:,start_error:end_error]\n",
    "\n",
    "        bposd_dec_partial = bposd_decoder(\n",
    "            window_pcm,\n",
    "            channel_probs=channel_probs[start_error:end_error], #assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "            max_iter=window_pcm.shape[1], #the maximum number of iterations for BP)\n",
    "            bp_method=\"ms\",\n",
    "            ms_scaling_factor=0, #min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "            osd_method=\"osd_cs\", #the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "            osd_order=min(pcm.shape[0],10) #the osd search depth\n",
    "        )\n",
    "\n",
    "        corr = bposd_dec_partial.decode(synd[r*m*ell:(r+window_size)*m*ell])\n",
    "        corr_inds = np.array([e + start_error for e in np.where(corr)[0]])\n",
    "        print(corr_inds)        \n",
    "        guessed_errors[corr_inds[corr_inds <= next_start_error]] = 1\n",
    "        print(np.where(guessed_errors)[0])\n",
    "        synd ^= (pcm @ guessed_errors).astype(np.bool_)\n",
    "\n",
    "\n",
    "decode_window(detection_events[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
